---
title: HuggingFace
sidebarTitle: 概览
description: Learn how to use HuggingFace 模型s in Agno.
---

Hugging Face provides a wide range of state-of-the-art language 模型s tailored to diverse NLP tasks,
including text generation, summarization, translation, and question answering.
These 模型s are available through the Hugging Face Transformers library and are widely
adopted due to their ease of use, flexibility, and comprehensive 文档ation.

Explore HuggingFace’s language 模型s [here](https://huggingface.co/docs/text-generation-推理/en/supported_模型s).

## Authentication

Set your `HF_TOKEN` environment. You can get one [from HuggingFace here](https://huggingface.co/settings/tokens).

<CodeGroup>

```bash Mac
export HF_TOKEN=***
```

```bash Windows
setx HF_TOKEN ***
```

</CodeGroup>

## Example

Use `HuggingFace` with your `Agent`:

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="meta-llama/Meta-Llama-3-8B-Instruct",
        max_tokens=4096,
    ),
    markdown=True
)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story.")
```

</CodeGroup>

<Note> 查看 更多功能 examples [here](/integrations/models/gateways/huggingface/usage/basic-stream). </Note>

## Parameters

| Parameter         | Type               | Default                           | Description                                                           |
| ----------------- | ------------------ | --------------------------------- | --------------------------------------------------------------------- |
| `id`              | `str`              | `"microsoft/DialoGPT-medium"`     | The id of the Hugging Face 模型 to use                              |
| `name`            | `str`              | `"HuggingFace"`                   | The name of the 模型                                                 |
| `提供商`        | `str`              | `"HuggingFace"`                   | The 提供商 of the 模型                                             |
| `api_key`         | `Optional[str]`    | `None`                            | The API key for Hugging Face (defaults to HF_TOKEN env var)          |
| `base_url`        | `str`              | `"https://api-推理.huggingface.co/模型s"` | The base URL for Hugging Face Inference API       |
| `wait_for_模型`  | `bool`             | `True`                            | Whether to wait for the 模型 to load if it's cold                   |
| `use_cache`       | `bool`             | `True`                            | Whether to use caching for faster 推理                           |
| `max_tokens`      | `Optional[int]`    | `None`                            | Maximum number of tokens to generate                                  |
| `temperature`     | `Optional[float]`  | `None`                            | Controls randomness in the 模型's output                             |
| `top_p`           | `Optional[float]`  | `None`                            | Controls diversity via nucleus sampling                               |
| `repetition_penalty` | `Optional[float]` | `None`                           | Penalty for repeating tokens (higher values reduce repetition)       |

`HuggingFace` is a subclass of the [Model](/reference/models/模型) class and has access to the same params.
