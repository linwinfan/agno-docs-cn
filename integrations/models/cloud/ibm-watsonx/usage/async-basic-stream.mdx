---
title: Async Streaming Agent
---

## Code

```python cookbook/11_models/ibm/watsonx/async_basic_stream.py
import asyncio

from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(
    model=WatsonX(id="ibm/granite-20b-code-instruct"), debug_mode=True, markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))
```

## 使用方法

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="安装 libraries">
    ```bash
    pip install -U ibm-watsonx-ai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/11_models/ibm/watsonx/async_basic_stream.py
    ```

    ```bash Windows
    python cookbook\models\ibm\watsonx\async_basic_stream.py
    ```
    </CodeGroup>
  </Step>
</Steps>

This example combines 异步 execution with streaming. It creates an 智能体 with `debug_mode=True` for additional logging and uses the 异步 API with streaming to get and display responses as they're generated.